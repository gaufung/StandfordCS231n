{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorï¼ŒMatrix and Tensor Derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Simplify\n",
    "Keep simple, and avoid doing to many thing at once.\n",
    "\n",
    "## 1.1 Expanding notation into explict sums and equaltions for each component\n",
    "Be useful to write out the explict formula for *a single scalar element* of the output in terms of nothing but *scalar variables*\n",
    "\n",
    "**Example**  \n",
    "Suppose we have a column vertor $\\vec{y}$ of lenght C that is calculated by forming the product a matrix $W$ that is $C$ rows by D columns with a column vector $\\vec{x}$ of length D:\n",
    "$$\\vec{y}=W\\vec{x}$$ \n",
    "If we want to calculate the 3rd component of $\\vec{y}$ with respect to the 7th component of $\\vec{x}$:\n",
    "$$\\frac{\\partial \\vec{y_{3}}}{\\partial \\vec{x_{7}}}$$\n",
    "The first thing to do is to write down the formula for computing $\\vec{y_3}$\n",
    "$$\\vec{y_3}=\\sum_{j=1}^{D}W_{3,j}\\vec{x_j}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Removing the summation notation\n",
    "We will make errors when differentating expression that contains summation notation $\\sum$ or product notation $\\prod$\n",
    "\n",
    "$$\\vec{y_3}=W_{3,1}\\vec{x_1}+W_{3,2}\\vec{x_2}+\\ldots+W_{3,7}\\vec{x_7}+\\ldots+W_{3,D}\\vec{x_{D}}$$\n",
    "So:\n",
    "$$\\frac{\\partial \\vec{y_3}}{\\partial \\vec{x_7}}=\\frac{\\partial}{\\partial \\vec{x_7}}[W_{3,1}\\vec{x_1}+W_{3,2}\\vec{x_2}+\\ldots+W_{3,7}\\vec{x_7}+\\ldots+W_{3,D}\\vec{x_{D}}] =\\frac{\\partial}{\\partial \\vec{y}}[W_{3,7}\\vec{x_7}]=W_{3,7}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 The Jacobian matrix\n",
    "Compute teh derivatives of each component of \\vec{y} with respect to each component of \\vec{x}, and we noted that there would be $C \\times D$ of these.\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial \\vec{y_1}}{\\partial \\vec{x_1}} & \\frac{\\partial \\vec{y_1}}{\\partial \\vec{x_2}} & \\ldots & \\frac{\\partial \\vec{y_1}}{\\partial \\vec{x_D}}  \\\\\n",
    "\\frac{\\partial \\vec{y_2}}{\\partial \\vec{x_1}} & \\frac{\\partial \\vec{y_2}}{\\partial \\vec{x_2}} & \\ldots & \\frac{\\partial \\vec{y_2}}{\\partial \\vec{x_D}}  \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial \\vec{y_C}}{\\partial \\vec{x_1}} & \\frac{\\partial \\vec{y_C}}{\\partial \\vec{x_2}} & \\ldots & \\frac{\\partial \\vec{y_C}}{\\partial \\vec{x_D}}  \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "this is called the *Jacobian matrix*. Thus, after all this work, we have concluded that for $$\\vec{y}=W\\vec{x}$$ We have $$\\frac{\\partial \\vec{y}}{\\partial \\vec{x}} = W$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Row vectors instead of Column vector\n",
    "When working with different neural network packages to pay close attenation to the arrangement of weight matrics, data matrics, and so on. $X$ contains many different vectors, each of which represents an input, is each data vector a row or column of the data matrix $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Example 2\n",
    "Let $\\vec{y}$ be a row vector with $C$ components computed by taking the product of another row vector $\\vec{x}$ with D components and a matrix $W$ that is $D$ rows by $C$ columns\n",
    "$$\\vec{y}=\\vec{x}W$$\n",
    "In this case, you wiil see, by writing $$\\vec{y_3}=\\sum_{j=1}^{D}\\vec{x_j}W_{j,3}$$\n",
    "that\n",
    "$$\\frac{\\partial \\vec{y_3}}{\\partial \\vec{x_7}}=W_{7,3}$$\n",
    "So\n",
    "$$\\frac{\\partial \\vec{y}}{\\partial \\vec{x}}=W$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Dealing with more than two dimensions\n",
    "Conider another closely related problem, that of computing\n",
    "$$\\frac{\\partial \\vec{y}}{\\partial W}$$\n",
    "\\vec{y} varies along one coordinate whhile $W$ varies along two coordinates. Thus, the entire derivative is most naturally contained in a *three dimensional array*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Use scalar notation\n",
    "$$\\vec{y_3}=\\vec{x_1}W_{1,3}+\\vec{x_2}W_{2,3}+\\ldots+\\vec{x_D}W_{D,3}$$\n",
    "In other word:\n",
    "$$\\frac{\\partial \\vec{y_3}}{\\partial W_{7,8}}=0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Generality\n",
    "In general, when the index of the $\\vec{y}$ component is equal to the second index of the $W$, the derivative will be non-zore, but will be zero otherwise, We can write:\n",
    "$$\\frac{\\partial \\vec{y_j}}{\\partial W_{i,j}}=\\vec{x_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we let $F$ represent the 3rd array representing the derivative of \\vec{y} with respect to $W$, where $F_{i,j,k}=\\frac{\\partial \\vec{y_i}}{\\partial W_{j,k}}$\n",
    "then \n",
    "$$F_{i,j,i}=\\vec{x_j}$$ but all other entries of $F$ are zeros.\n",
    "Finally, if we difine a new **two dimensional ** array G as\n",
    "$$G_{i,j}=F_{i,j,i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Multiple data points\n",
    "Using multple examples of $\\vec{x}$, stacked together to form a matrix $X$. Let us assume that each row represent individual $\\vec{x}$ with length D. that X is a two-dimensional array with N rows and D columns, W, as in our last example, will be a matrix with D rows and C columns, Y will become N rows and C columns. Each row of Y will give a row vector associated with the corresponding row of the input X.\n",
    "$$Y_{i,j}=\\sum_{k=1}^{D}X_{i,k}W_{k,j}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we let $Y_{i,:}$ be the ith row of $Y$ and let $X_{i,:}$ be the ith row of X, then we will see that $$\\frac{\\partial Y_{i,:}}{\\partial X_{i,:}}=W$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
